	.text
	.file	"llvmjit"
	.globl	eval
	.p2align	4, 0x90
	.type	eval,@function
eval:
	.cfi_startproc
	pushq	%rbp
	.cfi_def_cfa_offset 16
	pushq	%r15
	.cfi_def_cfa_offset 24
	pushq	%r14
	.cfi_def_cfa_offset 32
	pushq	%r13
	.cfi_def_cfa_offset 40
	pushq	%r12
	.cfi_def_cfa_offset 48
	pushq	%rbx
	.cfi_def_cfa_offset 56
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	.cfi_offset %rbp, -16
	movq	(%rdi), %rdx
	movq	8(%rdi), %rsi
	movq	24(%rdx), %rax
	movl	(%rax), %eax
	movl	944(%rsi), %ecx
	notl	%ecx
	movq	%rsi, -16(%rsp)
	movl	%eax, 944(%rsi)
	testl	%eax, %ecx
	je	.LBB0_5
	movq	(%rdx), %rsi
	movq	%rsi, -24(%rsp)
	movq	8(%rdx), %rax
	movq	(%rsi), %rcx
	xorq	(%rax), %rcx
	movq	-16(%rsp), %r14
	movq	%rcx, 768(%r14)
	movq	8(%rsi), %rcx
	xorq	8(%rax), %rcx
	movq	%rcx, 776(%r14)
	movzbl	256(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r12d
	shrl	$7, %r12d
	movq	%rdx, -8(%rsp)
	leal	(%r12,%r12,2), %edx
	leal	(%rdx,%r12,8), %edx
	shll	$4, %r12d
	orl	%edx, %r12d
	xorl	%ecx, %r12d
	movzbl	261(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	266(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	271(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -40(%rsp)
	xorl	%eax, %ebp
	movl	%r12d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -32(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -72(%rsp)
	xorl	%r8d, %r12d
	xorl	%edx, %r12d
	xorl	%ebp, %r12d
	movzbl	260(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %edx
	leal	(%rdx,%rbx,8), %edx
	shll	$4, %ebx
	orl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	265(%r14), %ecx
	movzbl	(%r14,%rcx), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	270(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	259(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %eax
	leal	(%rax,%rsi,8), %eax
	shll	$4, %esi
	orl	%eax, %esi
	xorl	%edi, %esi
	movl	%r8d, %eax
	xorl	%ecx, %eax
	xorl	%edx, %eax
	xorl	%esi, %eax
	xorl	%ebp, %eax
	movq	%rax, -80(%rsp)
	xorl	%r9d, %ebp
	movl	%ebx, %eax
	xorl	%ecx, %eax
	xorl	%edx, %eax
	xorl	%ebp, %eax
	movq	%rax, -48(%rsp)
	xorl	%r8d, %r9d
	movl	%ecx, %eax
	xorl	%ecx, %r9d
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %eax
	leal	(%rax,%rax,2), %edx
	leal	(%rdx,%rax,8), %edx
	shll	$4, %eax
	orl	%edx, %eax
	xorl	%ecx, %eax
	xorl	%eax, %r9d
	xorl	%esi, %r9d
	movq	%r9, -88(%rsp)
	xorl	%r8d, %ebx
	xorl	%eax, %ebx
	xorl	%ebp, %ebx
	movzbl	264(%r14), %eax
	movzbl	(%r14,%rax), %r10d
	movl	%r10d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r10d, %r8d
	shrl	$7, %r8d
	leal	(%r8,%r8,2), %edx
	leal	(%rdx,%r8,8), %edx
	shll	$4, %r8d
	orl	%edx, %r8d
	xorl	%ecx, %r8d
	movzbl	269(%r14), %ecx
	movzbl	(%r14,%rcx), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edx
	leal	(%rdx,%rsi,8), %edx
	shll	$4, %esi
	orl	%edx, %esi
	xorl	%ecx, %esi
	movzbl	258(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %edx
	movzbl	263(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%r8d, %ebp
	xorl	%ecx, %ebp
	xorl	%esi, %ebp
	movl	%ebp, %edi
	movl	%r10d, %r11d
	xorl	%ecx, %r11d
	xorl	%esi, %r11d
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebp
	leal	(%rbp,%rsi,8), %ebp
	shll	$4, %esi
	orl	%ebp, %esi
	xorl	%edx, %r11d
	xorl	%eax, %r11d
	xorl	%r9d, %eax
	xorl	%r10d, %r9d
	xorl	%ecx, %r9d
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %esi
	xorl	%esi, %r9d
	xorl	%edx, %r9d
	xorl	%r10d, %r8d
	xorl	%eax, %edi
	movl	%edi, -96(%rsp)
	xorl	%esi, %r8d
	xorl	%eax, %r8d
	movzbl	268(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %eax
	leal	(%rax,%rbp,8), %eax
	shll	$4, %ebp
	orl	%eax, %ebp
	movl	%ecx, %eax
	movl	%ecx, %r15d
	movl	%ecx, -104(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ebp
	movzbl	257(%r14), %eax
	movzbl	(%r14,%rax), %edi
	movl	%edi, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%edi, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	262(%r14), %eax
	movzbl	(%r14,%rax), %r10d
	movl	%r10d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %esi
	leal	(%rsi,%rax,8), %esi
	shll	$4, %eax
	orl	%esi, %eax
	movl	%r10d, %esi
	andl	$127, %esi
	addl	%esi, %esi
	xorl	%esi, %eax
	movzbl	267(%r14), %esi
	movzbl	(%r14,%rsi), %edx
	movl	%ebp, %esi
	xorl	%edx, %esi
	xorl	%ecx, %esi
	xorl	%edx, %r15d
	xorl	%ecx, %r15d
	movl	%edx, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %r13d
	leal	(%r13,%rcx,8), %r13d
	shll	$4, %ecx
	orl	%r13d, %ecx
	xorl	%eax, %r15d
	xorl	%r10d, %r15d
	xorl	%edi, %r10d
	movl	-104(%rsp), %r13d
	xorl	%r13d, %edi
	xorl	%edx, %edi
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %ecx
	xorl	%ecx, %edi
	xorl	%eax, %edi
	xorl	%r13d, %ebp
	xorl	%ecx, %ebp
	xorl	%r10d, %esi
	xorl	%r10d, %ebp
	movl	-72(%rsp), %eax
	shll	$16, %eax
	orl	-32(%rsp), %eax
	shll	$24, %r12d
	orl	%eax, %r12d
	movl	-40(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r12d
	movq	-48(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r12
	movq	-80(%rsp), %rax
	shlq	$40, %rax
	movq	-88(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %rbx
	orq	%rcx, %rbx
	orq	%r12, %rbx
	movq	%rbx, 608(%r14)
	shll	$8, %r11d
	shll	$16, %r9d
	orl	-96(%rsp), %r9d
	shll	$24, %r8d
	orl	%r9d, %r8d
	orl	%r11d, %r8d
	shlq	$32, %rsi
	orq	%rsi, %r8
	shlq	$40, %r15
	shlq	$48, %rdi
	orq	%r15, %rdi
	shlq	$56, %rbp
	orq	%rdi, %rbp
	orq	%r8, %rbp
	movq	%rbp, 616(%r14)
	movq	-24(%rsp), %rsi
	movl	4(%rsi), %r9d
	movl	%r9d, -40(%rsp)
	movl	12(%rsi), %r8d
	movl	%r8d, -48(%rsp)
	movzbl	12(%rsi), %eax
	movzbl	(%r14,%rax), %edi
	movzbl	15(%rsi), %eax
	movzbl	(%r14,%rax), %eax
	movzbl	14(%rsi), %ecx
	movzbl	(%r14,%rcx), %ecx
	movzbl	13(%rsi), %edx
	movzbl	(%r14,%rdx), %edx
	shll	$8, %ecx
	shll	$16, %eax
	shll	$24, %edi
	orl	%eax, %edi
	orl	%ecx, %edi
	orl	%edx, %edi
	xorl	(%rsi), %edi
	xorl	$1, %edi
	movl	%edi, %eax
	movq	%rdi, -32(%rsp)
	xorl	%r9d, %eax
	movl	%eax, %ecx
	xorl	8(%rsi), %ecx
	movl	%ecx, %esi
	movq	%rcx, %rdx
	movq	%rcx, -24(%rsp)
	xorl	%r8d, %esi
	movq	%rsi, -72(%rsp)
	shlq	$32, %rax
	leaq	(%rdi,%rax), %rax
	movq	%rax, 448(%r14)
	movq	%rsi, %rcx
	shlq	$32, %rcx
	leaq	(%rdx,%rcx), %rcx
	movq	%rcx, 456(%r14)
	xorq	%rax, %rbx
	movq	%rbx, 784(%r14)
	xorq	%rcx, %rbp
	movq	%rbp, 792(%r14)
	movzbl	272(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r12d
	shrl	$7, %r12d
	leal	(%r12,%r12,2), %edx
	leal	(%rdx,%r12,8), %edx
	shll	$4, %r12d
	orl	%edx, %r12d
	xorl	%ecx, %r12d
	movzbl	277(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	282(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	287(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -80(%rsp)
	xorl	%eax, %ebp
	movl	%r12d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -88(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -96(%rsp)
	xorl	%r8d, %r12d
	xorl	%edx, %r12d
	xorl	%ebp, %r12d
	movzbl	276(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %r10d
	shrl	$7, %r10d
	leal	(%r10,%r10,2), %edx
	leal	(%rdx,%r10,8), %edx
	shll	$4, %r10d
	orl	%edx, %r10d
	xorl	%ecx, %r10d
	movzbl	281(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	286(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	275(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%r10d, %ebp
	xorl	%edi, %ebp
	xorl	%edx, %ebp
	movq	%rbp, %rax
	movl	%r9d, %ebx
	xorl	%edi, %ebx
	xorl	%edx, %ebx
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	xorl	%esi, %ebx
	xorl	%ecx, %ebx
	movq	%rbx, -104(%rsp)
	xorl	%r8d, %ecx
	xorl	%r9d, %r8d
	xorl	%edi, %r8d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r8d
	xorl	%esi, %r8d
	movq	%r8, -56(%rsp)
	xorl	%r9d, %r10d
	xorl	%ecx, %eax
	movq	%rax, -64(%rsp)
	xorl	%edx, %r10d
	xorl	%ecx, %r10d
	movzbl	280(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %ecx
	leal	(%rcx,%rbp,8), %ecx
	shll	$4, %ebp
	orl	%ecx, %ebp
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %ebp
	movzbl	285(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ecx
	leal	(%rcx,%rsi,8), %ecx
	shll	$4, %esi
	orl	%ecx, %esi
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %esi
	movzbl	274(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebx
	leal	(%rbx,%rdx,8), %ebx
	shll	$4, %edx
	orl	%ebx, %edx
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %edx
	movzbl	279(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %ebx
	xorl	%ecx, %ebx
	xorl	%esi, %ebx
	movl	%ebx, %edi
	movl	%r9d, %r15d
	xorl	%ecx, %r15d
	xorl	%esi, %r15d
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edx, %r15d
	xorl	%eax, %r15d
	xorl	%r8d, %eax
	xorl	%r9d, %r8d
	xorl	%ecx, %r8d
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %esi
	xorl	%esi, %r8d
	xorl	%edx, %r8d
	xorl	%r9d, %ebp
	xorl	%esi, %ebp
	xorl	%eax, %edi
	movl	%edi, -112(%rsp)
	xorl	%eax, %ebp
	movzbl	284(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %eax
	leal	(%rax,%rbx,8), %eax
	shll	$4, %ebx
	orl	%eax, %ebx
	movl	%ecx, %eax
	movl	%ecx, %r11d
	movl	%ecx, -108(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ebx
	movzbl	273(%r14), %eax
	movzbl	(%r14,%rax), %edi
	movl	%edi, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%edi, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	278(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %esi
	leal	(%rsi,%rax,8), %esi
	shll	$4, %eax
	orl	%esi, %eax
	movl	%r9d, %esi
	andl	$127, %esi
	addl	%esi, %esi
	xorl	%esi, %eax
	movzbl	283(%r14), %esi
	movzbl	(%r14,%rsi), %edx
	movl	%ebx, %esi
	xorl	%edx, %esi
	xorl	%ecx, %esi
	xorl	%edx, %r11d
	xorl	%ecx, %r11d
	movl	%edx, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %r13d
	leal	(%r13,%rcx,8), %r13d
	shll	$4, %ecx
	orl	%r13d, %ecx
	xorl	%eax, %r11d
	xorl	%r9d, %r11d
	xorl	%edi, %r9d
	movl	-108(%rsp), %r13d
	xorl	%r13d, %edi
	xorl	%edx, %edi
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %ecx
	xorl	%ecx, %edi
	xorl	%eax, %edi
	xorl	%r13d, %ebx
	xorl	%ecx, %ebx
	xorl	%r9d, %esi
	xorl	%r9d, %ebx
	movl	-96(%rsp), %eax
	shll	$16, %eax
	orl	-88(%rsp), %eax
	shll	$24, %r12d
	orl	%eax, %r12d
	movl	-80(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r12d
	movq	-64(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r12
	movq	-104(%rsp), %rax
	shlq	$40, %rax
	movq	-56(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %r10
	orq	%rcx, %r10
	orq	%r12, %r10
	movq	%r10, 624(%r14)
	shll	$8, %r15d
	shll	$16, %r8d
	orl	-112(%rsp), %r8d
	shll	$24, %ebp
	orl	%r8d, %ebp
	orl	%r15d, %ebp
	shlq	$32, %rsi
	orq	%rsi, %rbp
	shlq	$40, %r11
	shlq	$48, %rdi
	orq	%r11, %rdi
	shlq	$56, %rbx
	orq	%rdi, %rbx
	orq	%rbp, %rbx
	movq	%rbx, 632(%r14)
	movq	-72(%rsp), %rdx
	movzbl	%dl, %eax
	movzbl	(%r14,%rax), %esi
	movq	%rdx, %rax
	shrq	$24, %rax
	movzbl	(%r14,%rax), %eax
	movl	%edx, %ecx
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	shrl	$8, %edx
	movzbl	%dl, %edx
	movzbl	(%r14,%rdx), %edx
	shll	$8, %ecx
	shll	$16, %eax
	shll	$24, %esi
	orl	%eax, %esi
	orl	%edx, %esi
	orl	%ecx, %esi
	xorl	$2, %esi
	movq	-32(%rsp), %rdx
	xorl	%esi, %edx
	movq	%rdx, -32(%rsp)
	xorl	-40(%rsp), %esi
	movq	%rsi, -40(%rsp)
	movl	%esi, %eax
	xorl	-24(%rsp), %eax
	movl	%esi, %edi
	xorl	-48(%rsp), %edi
	movq	%rdi, -80(%rsp)
	movq	%rsi, %rcx
	shlq	$32, %rcx
	leaq	(%rdx,%rcx), %rcx
	movq	%rcx, 464(%r14)
	movq	%rdi, %rdx
	shlq	$32, %rdx
	orq	%rdx, %rax
	movq	%rax, 472(%r14)
	xorq	%rcx, %r10
	movq	%r10, 800(%r14)
	xorq	%rbx, %rax
	movq	%rax, 808(%r14)
	movzbl	288(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r15d
	shrl	$7, %r15d
	leal	(%r15,%r15,2), %edx
	leal	(%rdx,%r15,8), %edx
	shll	$4, %r15d
	orl	%edx, %r15d
	xorl	%ecx, %r15d
	movzbl	293(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	298(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	303(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -72(%rsp)
	xorl	%eax, %ebp
	movl	%r15d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -88(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -96(%rsp)
	xorl	%r8d, %r15d
	xorl	%edx, %r15d
	xorl	%ebp, %r15d
	movzbl	292(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %edx
	leal	(%rdx,%rbx,8), %edx
	shll	$4, %ebx
	orl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	297(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	302(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	291(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebx, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movq	%rax, %r10
	movl	%r9d, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	xorl	%esi, %eax
	xorl	%ecx, %eax
	movq	%rax, -104(%rsp)
	xorl	%r8d, %ecx
	xorl	%r9d, %r8d
	xorl	%edi, %r8d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r8d
	xorl	%esi, %r8d
	movq	%r8, -56(%rsp)
	xorl	%r9d, %ebx
	xorl	%ecx, %r10d
	movq	%r10, -64(%rsp)
	xorl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	296(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %eax
	leal	(%rax,%rbp,8), %eax
	shll	$4, %ebp
	orl	%eax, %ebp
	movl	%r8d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ebp
	movzbl	301(%r14), %eax
	movzbl	(%r14,%rax), %r10d
	movl	%r10d, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%r10d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	290(%r14), %eax
	movzbl	(%r14,%rax), %eax
	movl	%eax, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%eax, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	295(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebp, %edx
	xorl	%edi, %edx
	xorl	%ecx, %edx
	movl	%edx, %r9d
	movl	%r8d, %r12d
	xorl	%edi, %r12d
	xorl	%ecx, %r12d
	movl	%edi, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %edx
	leal	(%rdx,%rcx,8), %edx
	shll	$4, %ecx
	orl	%edx, %ecx
	xorl	%esi, %r12d
	xorl	%eax, %r12d
	xorl	%r10d, %eax
	xorl	%r8d, %r10d
	xorl	%edi, %r10d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %ecx
	xorl	%ecx, %r10d
	xorl	%esi, %r10d
	xorl	%r8d, %ebp
	xorl	%ecx, %ebp
	xorl	%eax, %r9d
	movl	%r9d, -112(%rsp)
	xorl	%eax, %ebp
	movzbl	300(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %eax
	leal	(%rax,%rdx,8), %eax
	shll	$4, %edx
	orl	%eax, %edx
	movl	%ecx, %eax
	movl	%ecx, %esi
	movl	%ecx, -108(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %edx
	movzbl	289(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %edi
	shrl	$7, %edi
	leal	(%rdi,%rdi,2), %eax
	leal	(%rax,%rdi,8), %eax
	shll	$4, %edi
	orl	%eax, %edi
	movl	%r8d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %edi
	movzbl	294(%r14), %eax
	movzbl	(%r14,%rax), %r11d
	movl	%r11d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %ecx
	leal	(%rcx,%rax,8), %ecx
	shll	$4, %eax
	orl	%ecx, %eax
	movl	%r11d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %eax
	movzbl	299(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%edx, %r9d
	xorl	%ecx, %r9d
	xorl	%edi, %r9d
	xorl	%ecx, %esi
	xorl	%edi, %esi
	movl	%ecx, %edi
	shrl	$7, %edi
	leal	(%rdi,%rdi,2), %r13d
	leal	(%r13,%rdi,8), %r13d
	shll	$4, %edi
	orl	%r13d, %edi
	xorl	%eax, %esi
	xorl	%r11d, %esi
	xorl	%r8d, %r11d
	movl	-108(%rsp), %r13d
	xorl	%r13d, %r8d
	xorl	%ecx, %r8d
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %edi
	xorl	%edi, %r8d
	xorl	%eax, %r8d
	xorl	%r13d, %edx
	xorl	%edi, %edx
	xorl	%r11d, %r9d
	xorl	%r11d, %edx
	movl	-96(%rsp), %eax
	shll	$16, %eax
	orl	-88(%rsp), %eax
	shll	$24, %r15d
	orl	%eax, %r15d
	movl	-72(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r15d
	movq	-64(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r15
	movq	-104(%rsp), %rax
	shlq	$40, %rax
	movq	-56(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %rbx
	orq	%rcx, %rbx
	orq	%r15, %rbx
	movq	%rbx, 640(%r14)
	shll	$8, %r12d
	shll	$16, %r10d
	orl	-112(%rsp), %r10d
	shll	$24, %ebp
	orl	%r10d, %ebp
	orl	%r12d, %ebp
	shlq	$32, %r9
	orq	%r9, %rbp
	shlq	$40, %rsi
	shlq	$48, %r8
	orq	%rsi, %r8
	shlq	$56, %rdx
	orq	%r8, %rdx
	orq	%rbp, %rdx
	movq	%rdx, 648(%r14)
	movq	-80(%rsp), %rbp
	movzbl	%bpl, %eax
	movzbl	(%r14,%rax), %edi
	movq	%rbp, %rax
	shrq	$24, %rax
	movzbl	(%r14,%rax), %eax
	movl	%ebp, %ecx
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %esi
	shrl	$8, %esi
	movzbl	%sil, %esi
	movzbl	(%r14,%rsi), %esi
	shll	$8, %ecx
	shll	$16, %eax
	shll	$24, %edi
	orl	%eax, %edi
	orl	%esi, %edi
	orl	%ecx, %edi
	xorl	-32(%rsp), %edi
	xorl	$4, %edi
	movl	%edi, %eax
	xorl	-40(%rsp), %eax
	movq	-24(%rsp), %rcx
	xorl	%edi, %ecx
	movq	%rdi, -72(%rsp)
	xorl	%ecx, %ebp
	movq	%rbp, -80(%rsp)
	movq	%rcx, %rsi
	movq	%rcx, -24(%rsp)
	shlq	$32, %rax
	leaq	(%rdi,%rax), %rax
	movq	%rax, 480(%r14)
	movq	%rbp, %rcx
	shlq	$32, %rcx
	leaq	(%rsi,%rcx), %rcx
	movq	%rcx, 488(%r14)
	xorq	%rax, %rbx
	movq	%rbx, 816(%r14)
	xorq	%rcx, %rdx
	movq	%rdx, 824(%r14)
	movzbl	304(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r15d
	shrl	$7, %r15d
	leal	(%r15,%r15,2), %edx
	leal	(%rdx,%r15,8), %edx
	shll	$4, %r15d
	orl	%edx, %r15d
	xorl	%ecx, %r15d
	movzbl	309(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	314(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	319(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -32(%rsp)
	xorl	%eax, %ebp
	movl	%r15d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -88(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -96(%rsp)
	xorl	%r8d, %r15d
	xorl	%edx, %r15d
	xorl	%ebp, %r15d
	movzbl	308(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %edx
	leal	(%rdx,%rbx,8), %edx
	shll	$4, %ebx
	orl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	313(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	318(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	307(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebx, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movq	%rax, %r10
	movl	%r9d, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	xorl	%esi, %eax
	xorl	%ecx, %eax
	movq	%rax, -104(%rsp)
	xorl	%r8d, %ecx
	xorl	%r9d, %r8d
	xorl	%edi, %r8d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r8d
	xorl	%esi, %r8d
	movq	%r8, -56(%rsp)
	xorl	%r9d, %ebx
	xorl	%ecx, %r10d
	movq	%r10, -64(%rsp)
	xorl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	312(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %ecx
	leal	(%rcx,%rbp,8), %ecx
	shll	$4, %ebp
	orl	%ecx, %ebp
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %ebp
	movzbl	317(%r14), %ecx
	movzbl	(%r14,%rcx), %r9d
	movl	%r9d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ecx
	leal	(%rcx,%rdx,8), %ecx
	shll	$4, %edx
	orl	%ecx, %edx
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %edx
	movzbl	306(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %edi
	shrl	$7, %edi
	leal	(%rdi,%rdi,2), %esi
	leal	(%rsi,%rdi,8), %esi
	shll	$4, %edi
	orl	%esi, %edi
	movl	%ecx, %esi
	andl	$127, %esi
	addl	%esi, %esi
	xorl	%esi, %edi
	movzbl	311(%r14), %esi
	movzbl	(%r14,%rsi), %esi
	movl	%ebp, %eax
	xorl	%esi, %eax
	xorl	%edx, %eax
	movl	%eax, %r10d
	movl	%r8d, %r11d
	xorl	%esi, %r11d
	xorl	%edx, %r11d
	movl	%esi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %eax
	leal	(%rax,%rdx,8), %eax
	shll	$4, %edx
	orl	%eax, %edx
	xorl	%edi, %r11d
	xorl	%ecx, %r11d
	xorl	%r9d, %ecx
	xorl	%r8d, %r9d
	xorl	%esi, %r9d
	andl	$127, %esi
	addl	%esi, %esi
	xorl	%esi, %edx
	xorl	%edx, %r9d
	xorl	%edi, %r9d
	xorl	%r8d, %ebp
	xorl	%edx, %ebp
	xorl	%ecx, %r10d
	movl	%r10d, -112(%rsp)
	xorl	%ecx, %ebp
	movzbl	316(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %edi
	shrl	$7, %edi
	leal	(%rdi,%rdi,2), %eax
	leal	(%rax,%rdi,8), %eax
	shll	$4, %edi
	orl	%eax, %edi
	movl	%ecx, %eax
	movl	%ecx, %r12d
	movl	%ecx, -108(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %edi
	movzbl	305(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%r8d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	310(%r14), %eax
	movzbl	(%r14,%rax), %r10d
	movl	%r10d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %esi
	leal	(%rsi,%rax,8), %esi
	shll	$4, %eax
	orl	%esi, %eax
	movl	%r10d, %esi
	andl	$127, %esi
	addl	%esi, %esi
	xorl	%esi, %eax
	movzbl	315(%r14), %esi
	movzbl	(%r14,%rsi), %edx
	movl	%edi, %esi
	xorl	%edx, %esi
	xorl	%ecx, %esi
	xorl	%edx, %r12d
	xorl	%ecx, %r12d
	movl	%edx, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %r13d
	leal	(%r13,%rcx,8), %r13d
	shll	$4, %ecx
	orl	%r13d, %ecx
	xorl	%eax, %r12d
	xorl	%r10d, %r12d
	xorl	%r8d, %r10d
	movl	-108(%rsp), %r13d
	xorl	%r13d, %r8d
	xorl	%edx, %r8d
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %ecx
	xorl	%ecx, %r8d
	xorl	%eax, %r8d
	xorl	%r13d, %edi
	xorl	%ecx, %edi
	xorl	%r10d, %esi
	xorl	%r10d, %edi
	movl	-96(%rsp), %eax
	shll	$16, %eax
	orl	-88(%rsp), %eax
	shll	$24, %r15d
	orl	%eax, %r15d
	movl	-32(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r15d
	movq	-64(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r15
	movq	-104(%rsp), %rax
	shlq	$40, %rax
	movq	-56(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %rbx
	orq	%rcx, %rbx
	orq	%r15, %rbx
	movq	%rbx, 656(%r14)
	shll	$8, %r11d
	shll	$16, %r9d
	orl	-112(%rsp), %r9d
	shll	$24, %ebp
	orl	%r9d, %ebp
	orl	%r11d, %ebp
	shlq	$32, %rsi
	orq	%rsi, %rbp
	shlq	$40, %r12
	shlq	$48, %r8
	orq	%r12, %r8
	shlq	$56, %rdi
	orq	%r8, %rdi
	orq	%rbp, %rdi
	movq	%rdi, 664(%r14)
	movq	-80(%rsp), %rdx
	movzbl	%dl, %eax
	movzbl	(%r14,%rax), %esi
	movq	%rdx, %rax
	shrq	$24, %rax
	movzbl	(%r14,%rax), %eax
	movl	%edx, %ecx
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	shrl	$8, %edx
	movzbl	%dl, %edx
	movzbl	(%r14,%rdx), %edx
	shll	$8, %ecx
	shll	$16, %eax
	shll	$24, %esi
	orl	%eax, %esi
	orl	%edx, %esi
	orl	%ecx, %esi
	xorl	$8, %esi
	movq	-72(%rsp), %rdx
	xorl	%esi, %edx
	movq	%rdx, -72(%rsp)
	movq	-40(%rsp), %rcx
	xorl	%esi, %ecx
	movq	%rcx, -40(%rsp)
	movl	%ecx, %eax
	xorl	-24(%rsp), %eax
	xorl	-48(%rsp), %esi
	movq	%rsi, -32(%rsp)
	shlq	$32, %rcx
	leaq	(%rdx,%rcx), %rcx
	movq	%rcx, 496(%r14)
	movq	%rsi, %rdx
	shlq	$32, %rdx
	orq	%rdx, %rax
	movq	%rax, 504(%r14)
	xorq	%rcx, %rbx
	movq	%rbx, 832(%r14)
	xorq	%rdi, %rax
	movq	%rax, 840(%r14)
	movzbl	320(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r13d
	shrl	$7, %r13d
	leal	(%r13,%r13,2), %edx
	leal	(%rdx,%r13,8), %edx
	shll	$4, %r13d
	orl	%edx, %r13d
	xorl	%ecx, %r13d
	movzbl	325(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	330(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	335(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -80(%rsp)
	xorl	%eax, %ebp
	movl	%r13d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -48(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -88(%rsp)
	xorl	%r8d, %r13d
	xorl	%edx, %r13d
	xorl	%ebp, %r13d
	movzbl	324(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %edx
	leal	(%rdx,%rbx,8), %edx
	shll	$4, %ebx
	orl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	329(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	334(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	323(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebx, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movq	%rax, %r10
	movl	%r9d, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	xorl	%esi, %eax
	xorl	%ecx, %eax
	movq	%rax, -96(%rsp)
	xorl	%r8d, %ecx
	xorl	%r9d, %r8d
	xorl	%edi, %r8d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r8d
	xorl	%esi, %r8d
	movq	%r8, -104(%rsp)
	xorl	%ecx, %r10d
	movq	%r10, -56(%rsp)
	xorl	%r9d, %ebx
	xorl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	328(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %r8d
	shrl	$7, %r8d
	leal	(%r8,%r8,2), %eax
	leal	(%rax,%r8,8), %eax
	shll	$4, %r8d
	orl	%eax, %r8d
	movl	%r9d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %r8d
	movzbl	333(%r14), %eax
	movzbl	(%r14,%rax), %r10d
	movl	%r10d, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%r10d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	322(%r14), %eax
	movzbl	(%r14,%rax), %edx
	movl	%edx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebp
	leal	(%rbp,%rsi,8), %ebp
	shll	$4, %esi
	orl	%ebp, %esi
	movl	%edx, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %esi
	movzbl	327(%r14), %eax
	movzbl	(%r14,%rax), %eax
	movl	%r8d, %ebp
	xorl	%eax, %ebp
	xorl	%ecx, %ebp
	movl	%ebp, %edi
	movl	%r9d, %r12d
	xorl	%eax, %r12d
	xorl	%ecx, %r12d
	movl	%eax, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %ebp
	leal	(%rbp,%rcx,8), %ebp
	shll	$4, %ecx
	orl	%ebp, %ecx
	xorl	%esi, %r12d
	xorl	%edx, %r12d
	xorl	%r10d, %edx
	xorl	%r9d, %r10d
	xorl	%eax, %r10d
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	xorl	%ecx, %r10d
	xorl	%esi, %r10d
	xorl	%r9d, %r8d
	xorl	%ecx, %r8d
	xorl	%edx, %edi
	movl	%edi, -64(%rsp)
	xorl	%edx, %r8d
	movzbl	332(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %eax
	leal	(%rax,%rbp,8), %eax
	shll	$4, %ebp
	orl	%eax, %ebp
	movl	%ecx, %eax
	movl	%ecx, %esi
	movl	%ecx, -112(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ebp
	movzbl	321(%r14), %eax
	movzbl	(%r14,%rax), %edi
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %eax
	leal	(%rax,%rdx,8), %eax
	shll	$4, %edx
	orl	%eax, %edx
	movl	%edi, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %edx
	movzbl	326(%r14), %eax
	movzbl	(%r14,%rax), %r11d
	movl	%r11d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %ecx
	leal	(%rcx,%rax,8), %ecx
	shll	$4, %eax
	orl	%ecx, %eax
	movl	%r11d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %eax
	movzbl	331(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %r9d
	xorl	%ecx, %r9d
	xorl	%edx, %r9d
	xorl	%ecx, %esi
	xorl	%edx, %esi
	movl	%ecx, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %r15d
	leal	(%r15,%rdx,8), %r15d
	shll	$4, %edx
	orl	%r15d, %edx
	xorl	%eax, %esi
	xorl	%r11d, %esi
	xorl	%edi, %r11d
	movl	-112(%rsp), %r15d
	xorl	%r15d, %edi
	xorl	%ecx, %edi
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %edx
	xorl	%edx, %edi
	xorl	%eax, %edi
	xorl	%r15d, %ebp
	xorl	%edx, %ebp
	xorl	%r11d, %r9d
	xorl	%r11d, %ebp
	movl	-88(%rsp), %eax
	shll	$16, %eax
	orl	-48(%rsp), %eax
	shll	$24, %r13d
	orl	%eax, %r13d
	movl	-80(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r13d
	movq	-56(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r13
	movq	-96(%rsp), %rax
	shlq	$40, %rax
	movq	-104(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %rbx
	orq	%rcx, %rbx
	orq	%r13, %rbx
	movq	%rbx, 672(%r14)
	shll	$8, %r12d
	shll	$16, %r10d
	orl	-64(%rsp), %r10d
	shll	$24, %r8d
	orl	%r10d, %r8d
	orl	%r12d, %r8d
	shlq	$32, %r9
	orq	%r9, %r8
	shlq	$40, %rsi
	shlq	$48, %rdi
	orq	%rsi, %rdi
	shlq	$56, %rbp
	orq	%rdi, %rbp
	orq	%r8, %rbp
	movq	%rbp, 680(%r14)
	movq	-32(%rsp), %rsi
	movzbl	%sil, %eax
	movzbl	(%r14,%rax), %edi
	movq	%rsi, %rax
	shrq	$24, %rax
	movzbl	(%r14,%rax), %eax
	movl	%esi, %ecx
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%esi, %edx
	shrl	$8, %edx
	movzbl	%dl, %edx
	movzbl	(%r14,%rdx), %edx
	shll	$8, %ecx
	shll	$16, %eax
	shll	$24, %edi
	orl	%eax, %edi
	orl	%edx, %edi
	orl	%ecx, %edi
	xorl	-72(%rsp), %edi
	xorl	$16, %edi
	movl	%edi, %eax
	xorl	-40(%rsp), %eax
	movq	-24(%rsp), %rcx
	xorl	%edi, %ecx
	movq	%rdi, -72(%rsp)
	movl	%ecx, %edx
	movq	%rcx, %r8
	movq	%rcx, -24(%rsp)
	xorl	%esi, %edx
	movq	%rdx, -80(%rsp)
	shlq	$32, %rax
	leaq	(%rdi,%rax), %rax
	movq	%rax, 512(%r14)
	movq	%rdx, %rcx
	shlq	$32, %rcx
	leaq	(%r8,%rcx), %rcx
	movq	%rcx, 520(%r14)
	xorq	%rax, %rbx
	movq	%rbx, 848(%r14)
	xorq	%rcx, %rbp
	movq	%rbp, 856(%r14)
	movzbl	336(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r12d
	shrl	$7, %r12d
	leal	(%r12,%r12,2), %edx
	leal	(%rdx,%r12,8), %edx
	shll	$4, %r12d
	orl	%edx, %r12d
	xorl	%ecx, %r12d
	movzbl	341(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	346(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	351(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -48(%rsp)
	xorl	%eax, %ebp
	movl	%r12d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -88(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -96(%rsp)
	xorl	%r8d, %r12d
	xorl	%edx, %r12d
	xorl	%ebp, %r12d
	movzbl	340(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %edx
	leal	(%rdx,%rbx,8), %edx
	shll	$4, %ebx
	orl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	345(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	350(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	339(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebx, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movq	%rax, %r10
	movl	%r9d, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	xorl	%esi, %eax
	xorl	%ecx, %eax
	movq	%rax, -104(%rsp)
	xorl	%r8d, %ecx
	xorl	%r9d, %r8d
	xorl	%edi, %r8d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r8d
	xorl	%esi, %r8d
	movq	%r8, -56(%rsp)
	xorl	%r9d, %ebx
	xorl	%ecx, %r10d
	movq	%r10, -64(%rsp)
	xorl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	344(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %ecx
	leal	(%rcx,%rbp,8), %ecx
	shll	$4, %ebp
	orl	%ecx, %ebp
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %ebp
	movzbl	349(%r14), %ecx
	movzbl	(%r14,%rcx), %r10d
	movl	%r10d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ecx
	leal	(%rcx,%rdx,8), %ecx
	shll	$4, %edx
	orl	%ecx, %edx
	movl	%r10d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %edx
	movzbl	338(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	343(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebp, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movl	%eax, %r9d
	movl	%r8d, %r15d
	xorl	%edi, %r15d
	xorl	%edx, %r15d
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %eax
	leal	(%rax,%rdx,8), %eax
	shll	$4, %edx
	orl	%eax, %edx
	xorl	%esi, %r15d
	xorl	%ecx, %r15d
	xorl	%r10d, %ecx
	xorl	%r8d, %r10d
	xorl	%edi, %r10d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r10d
	xorl	%esi, %r10d
	xorl	%r8d, %ebp
	xorl	%edx, %ebp
	xorl	%ecx, %r9d
	movl	%r9d, -112(%rsp)
	xorl	%ecx, %ebp
	movzbl	348(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %edi
	shrl	$7, %edi
	leal	(%rdi,%rdi,2), %eax
	leal	(%rax,%rdi,8), %eax
	shll	$4, %edi
	orl	%eax, %edi
	movl	%ecx, %eax
	movl	%ecx, %r13d
	movl	%ecx, -108(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %edi
	movzbl	337(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%r8d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	342(%r14), %eax
	movzbl	(%r14,%rax), %r11d
	movl	%r11d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %esi
	leal	(%rsi,%rax,8), %esi
	shll	$4, %eax
	orl	%esi, %eax
	movl	%r11d, %esi
	andl	$127, %esi
	addl	%esi, %esi
	xorl	%esi, %eax
	movzbl	347(%r14), %esi
	movzbl	(%r14,%rsi), %edx
	movl	%edi, %r9d
	xorl	%edx, %r9d
	xorl	%ecx, %r9d
	movl	%r13d, %esi
	xorl	%edx, %esi
	xorl	%ecx, %esi
	movl	%edx, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %r13d
	leal	(%r13,%rcx,8), %r13d
	shll	$4, %ecx
	orl	%r13d, %ecx
	xorl	%eax, %esi
	xorl	%r11d, %esi
	xorl	%r8d, %r11d
	movl	-108(%rsp), %r13d
	xorl	%r13d, %r8d
	xorl	%edx, %r8d
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %ecx
	xorl	%ecx, %r8d
	xorl	%eax, %r8d
	xorl	%r13d, %edi
	xorl	%ecx, %edi
	xorl	%r11d, %r9d
	xorl	%r11d, %edi
	movl	-96(%rsp), %eax
	shll	$16, %eax
	orl	-88(%rsp), %eax
	shll	$24, %r12d
	orl	%eax, %r12d
	movl	-48(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r12d
	movq	-64(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r12
	movq	-104(%rsp), %rax
	shlq	$40, %rax
	movq	-56(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %rbx
	orq	%rcx, %rbx
	orq	%r12, %rbx
	movq	%rbx, 688(%r14)
	shll	$8, %r15d
	shll	$16, %r10d
	orl	-112(%rsp), %r10d
	shll	$24, %ebp
	orl	%r10d, %ebp
	orl	%r15d, %ebp
	shlq	$32, %r9
	orq	%r9, %rbp
	shlq	$40, %rsi
	shlq	$48, %r8
	orq	%rsi, %r8
	shlq	$56, %rdi
	orq	%r8, %rdi
	orq	%rbp, %rdi
	movq	%rdi, 696(%r14)
	movq	-80(%rsp), %rdx
	movzbl	%dl, %eax
	movzbl	(%r14,%rax), %esi
	movq	%rdx, %rax
	shrq	$24, %rax
	movzbl	(%r14,%rax), %eax
	movl	%edx, %ecx
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	shrl	$8, %edx
	movzbl	%dl, %edx
	movzbl	(%r14,%rdx), %edx
	shll	$8, %ecx
	shll	$16, %eax
	shll	$24, %esi
	orl	%eax, %esi
	orl	%edx, %esi
	orl	%ecx, %esi
	xorl	$32, %esi
	movq	-72(%rsp), %rbp
	xorl	%esi, %ebp
	movq	%rbp, -72(%rsp)
	xorl	-40(%rsp), %esi
	movq	%rsi, -40(%rsp)
	movl	%esi, %eax
	xorl	-24(%rsp), %eax
	movl	%esi, %edx
	xorl	-32(%rsp), %edx
	movq	%rdx, -80(%rsp)
	movq	%rsi, %rcx
	shlq	$32, %rcx
	leaq	(%rbp,%rcx), %rcx
	movq	%rcx, 528(%r14)
	shlq	$32, %rdx
	orq	%rdx, %rax
	movq	%rax, 536(%r14)
	xorq	%rcx, %rbx
	movq	%rbx, 864(%r14)
	xorq	%rdi, %rax
	movq	%rax, 872(%r14)
	movzbl	352(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r12d
	shrl	$7, %r12d
	leal	(%r12,%r12,2), %edx
	leal	(%rdx,%r12,8), %edx
	shll	$4, %r12d
	orl	%edx, %r12d
	xorl	%ecx, %r12d
	movzbl	357(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	362(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	367(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -48(%rsp)
	xorl	%eax, %ebp
	movl	%r12d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -88(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -96(%rsp)
	xorl	%r8d, %r12d
	xorl	%edx, %r12d
	xorl	%ebp, %r12d
	movzbl	356(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %edx
	leal	(%rdx,%rbx,8), %edx
	shll	$4, %ebx
	orl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	361(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	366(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	355(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebx, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movq	%rax, %r10
	movl	%r9d, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	xorl	%esi, %eax
	xorl	%ecx, %eax
	movq	%rax, -104(%rsp)
	xorl	%r8d, %ecx
	xorl	%r9d, %r8d
	xorl	%edi, %r8d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r8d
	xorl	%esi, %r8d
	movq	%r8, -56(%rsp)
	xorl	%r9d, %ebx
	xorl	%ecx, %r10d
	movq	%r10, -64(%rsp)
	xorl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	360(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %eax
	leal	(%rax,%rbp,8), %eax
	shll	$4, %ebp
	orl	%eax, %ebp
	movl	%r8d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ebp
	movzbl	365(%r14), %eax
	movzbl	(%r14,%rax), %r10d
	movl	%r10d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %eax
	leal	(%rax,%rdx,8), %eax
	shll	$4, %edx
	orl	%eax, %edx
	movl	%r10d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %edx
	movzbl	354(%r14), %eax
	movzbl	(%r14,%rax), %eax
	movl	%eax, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%eax, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	359(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebp, %ecx
	xorl	%edi, %ecx
	xorl	%edx, %ecx
	movl	%ecx, %r9d
	movl	%r8d, %r15d
	xorl	%edi, %r15d
	xorl	%edx, %r15d
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ecx
	leal	(%rcx,%rdx,8), %ecx
	shll	$4, %edx
	orl	%ecx, %edx
	xorl	%esi, %r15d
	xorl	%eax, %r15d
	xorl	%r10d, %eax
	xorl	%r8d, %r10d
	xorl	%edi, %r10d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r10d
	xorl	%esi, %r10d
	xorl	%r8d, %ebp
	xorl	%edx, %ebp
	xorl	%eax, %r9d
	movl	%r9d, -112(%rsp)
	xorl	%eax, %ebp
	movzbl	364(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %r8d
	shrl	$7, %r8d
	leal	(%r8,%r8,2), %eax
	leal	(%rax,%r8,8), %eax
	shll	$4, %r8d
	orl	%eax, %r8d
	movl	%ecx, %eax
	movl	%ecx, %r13d
	movl	%ecx, -108(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %r8d
	movzbl	353(%r14), %eax
	movzbl	(%r14,%rax), %esi
	movl	%esi, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%esi, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	358(%r14), %eax
	movzbl	(%r14,%rax), %r11d
	movl	%r11d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %edi
	leal	(%rdi,%rax,8), %edi
	shll	$4, %eax
	orl	%edi, %eax
	movl	%r11d, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %eax
	movzbl	363(%r14), %edi
	movzbl	(%r14,%rdi), %edx
	movl	%r8d, %r9d
	xorl	%edx, %r9d
	xorl	%ecx, %r9d
	movl	%r13d, %edi
	xorl	%edx, %edi
	xorl	%ecx, %edi
	movl	%edx, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %r13d
	leal	(%r13,%rcx,8), %r13d
	shll	$4, %ecx
	orl	%r13d, %ecx
	xorl	%eax, %edi
	xorl	%r11d, %edi
	xorl	%esi, %r11d
	movl	-108(%rsp), %r13d
	xorl	%r13d, %esi
	xorl	%edx, %esi
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %ecx
	xorl	%ecx, %esi
	xorl	%eax, %esi
	xorl	%r13d, %r8d
	xorl	%ecx, %r8d
	xorl	%r11d, %r9d
	xorl	%r11d, %r8d
	movl	-96(%rsp), %eax
	shll	$16, %eax
	orl	-88(%rsp), %eax
	shll	$24, %r12d
	orl	%eax, %r12d
	movl	-48(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r12d
	movq	-64(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r12
	movq	-104(%rsp), %rax
	shlq	$40, %rax
	movq	-56(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %rbx
	orq	%rcx, %rbx
	orq	%r12, %rbx
	movq	%rbx, 704(%r14)
	shll	$8, %r15d
	shll	$16, %r10d
	orl	-112(%rsp), %r10d
	shll	$24, %ebp
	orl	%r10d, %ebp
	orl	%r15d, %ebp
	shlq	$32, %r9
	orq	%r9, %rbp
	shlq	$40, %rdi
	shlq	$48, %rsi
	orq	%rdi, %rsi
	shlq	$56, %r8
	orq	%rsi, %r8
	orq	%rbp, %r8
	movq	%r8, 712(%r14)
	movq	-80(%rsp), %rdi
	movzbl	%dil, %eax
	movzbl	(%r14,%rax), %esi
	movq	%rdi, %rax
	shrq	$24, %rax
	movzbl	(%r14,%rax), %eax
	movl	%edi, %ecx
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%edi, %edx
	shrl	$8, %edx
	movzbl	%dl, %edx
	movzbl	(%r14,%rdx), %edx
	shll	$8, %ecx
	shll	$16, %eax
	shll	$24, %esi
	orl	%eax, %esi
	orl	%edx, %esi
	orl	%ecx, %esi
	xorl	-72(%rsp), %esi
	xorl	$64, %esi
	movl	%esi, %eax
	xorl	-40(%rsp), %eax
	movq	-24(%rsp), %rcx
	xorl	%esi, %ecx
	movq	%rsi, -72(%rsp)
	xorl	%ecx, %edi
	movq	%rdi, -80(%rsp)
	movq	%rcx, %rdx
	movq	%rcx, -24(%rsp)
	shlq	$32, %rax
	leaq	(%rsi,%rax), %rax
	movq	%rax, 544(%r14)
	movq	%rdi, %rcx
	shlq	$32, %rcx
	leaq	(%rdx,%rcx), %rcx
	movq	%rcx, 552(%r14)
	xorq	%rax, %rbx
	movq	%rbx, 880(%r14)
	xorq	%rcx, %r8
	movq	%r8, 888(%r14)
	movzbl	368(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r12d
	shrl	$7, %r12d
	leal	(%r12,%r12,2), %edx
	leal	(%rdx,%r12,8), %edx
	shll	$4, %r12d
	orl	%edx, %r12d
	xorl	%ecx, %r12d
	movzbl	373(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	378(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	383(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -48(%rsp)
	xorl	%eax, %ebp
	movl	%r12d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -88(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -96(%rsp)
	xorl	%r8d, %r12d
	xorl	%edx, %r12d
	xorl	%ebp, %r12d
	movzbl	372(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %edx
	leal	(%rdx,%rbx,8), %edx
	shll	$4, %ebx
	orl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	377(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	382(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	371(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebx, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movq	%rax, %r10
	movl	%r9d, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	xorl	%esi, %eax
	xorl	%ecx, %eax
	movq	%rax, -104(%rsp)
	xorl	%r8d, %ecx
	xorl	%r9d, %r8d
	xorl	%edi, %r8d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r8d
	xorl	%esi, %r8d
	movq	%r8, -56(%rsp)
	xorl	%r9d, %ebx
	xorl	%ecx, %r10d
	movq	%r10, -64(%rsp)
	xorl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	376(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %eax
	leal	(%rax,%rbp,8), %eax
	shll	$4, %ebp
	orl	%eax, %ebp
	movl	%r8d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ebp
	movzbl	381(%r14), %eax
	movzbl	(%r14,%rax), %r10d
	movl	%r10d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %eax
	leal	(%rax,%rdx,8), %eax
	shll	$4, %edx
	orl	%eax, %edx
	movl	%r10d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %edx
	movzbl	370(%r14), %eax
	movzbl	(%r14,%rax), %eax
	movl	%eax, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%eax, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	375(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebp, %ecx
	xorl	%edi, %ecx
	xorl	%edx, %ecx
	movl	%ecx, %r9d
	movl	%r8d, %r15d
	xorl	%edi, %r15d
	xorl	%edx, %r15d
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ecx
	leal	(%rcx,%rdx,8), %ecx
	shll	$4, %edx
	orl	%ecx, %edx
	xorl	%esi, %r15d
	xorl	%eax, %r15d
	xorl	%r10d, %eax
	xorl	%r8d, %r10d
	xorl	%edi, %r10d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r10d
	xorl	%esi, %r10d
	xorl	%r8d, %ebp
	xorl	%edx, %ebp
	xorl	%eax, %r9d
	movl	%r9d, -112(%rsp)
	xorl	%eax, %ebp
	movzbl	380(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %eax
	leal	(%rax,%rsi,8), %eax
	shll	$4, %esi
	orl	%eax, %esi
	movl	%ecx, %eax
	movl	%ecx, %edi
	movl	%ecx, -108(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %esi
	movzbl	369(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%r8d, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	374(%r14), %eax
	movzbl	(%r14,%rax), %r11d
	movl	%r11d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %edx
	leal	(%rdx,%rax,8), %edx
	shll	$4, %eax
	orl	%edx, %eax
	movl	%r11d, %edx
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %eax
	movzbl	379(%r14), %edx
	movzbl	(%r14,%rdx), %edx
	movl	%esi, %r9d
	xorl	%edx, %r9d
	xorl	%ecx, %r9d
	xorl	%edx, %edi
	xorl	%ecx, %edi
	movl	%edx, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %r13d
	leal	(%r13,%rcx,8), %r13d
	shll	$4, %ecx
	orl	%r13d, %ecx
	xorl	%eax, %edi
	xorl	%r11d, %edi
	xorl	%r8d, %r11d
	movl	-108(%rsp), %r13d
	xorl	%r13d, %r8d
	xorl	%edx, %r8d
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %ecx
	xorl	%ecx, %r8d
	xorl	%eax, %r8d
	xorl	%r13d, %esi
	xorl	%ecx, %esi
	xorl	%r11d, %r9d
	xorl	%r11d, %esi
	movl	-96(%rsp), %eax
	shll	$16, %eax
	orl	-88(%rsp), %eax
	shll	$24, %r12d
	orl	%eax, %r12d
	movl	-48(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r12d
	movq	-64(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r12
	movq	-104(%rsp), %rax
	shlq	$40, %rax
	movq	-56(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %rbx
	orq	%rcx, %rbx
	orq	%r12, %rbx
	movq	%rbx, 720(%r14)
	shll	$8, %r15d
	shll	$16, %r10d
	orl	-112(%rsp), %r10d
	shll	$24, %ebp
	orl	%r10d, %ebp
	orl	%r15d, %ebp
	shlq	$32, %r9
	orq	%r9, %rbp
	shlq	$40, %rdi
	shlq	$48, %r8
	orq	%rdi, %r8
	shlq	$56, %rsi
	orq	%r8, %rsi
	orq	%rbp, %rsi
	movq	%rsi, 728(%r14)
	movq	-80(%rsp), %rdx
	movzbl	%dl, %eax
	movzbl	(%r14,%rax), %edi
	movq	%rdx, %rax
	shrq	$24, %rax
	movzbl	(%r14,%rax), %eax
	movl	%edx, %ecx
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	shrl	$8, %edx
	movzbl	%dl, %edx
	movzbl	(%r14,%rdx), %edx
	shll	$8, %ecx
	shll	$16, %eax
	shll	$24, %edi
	orl	%eax, %edi
	orl	%edx, %edi
	orl	%ecx, %edi
	xorl	$128, %edi
	movq	-72(%rsp), %rdx
	xorl	%edi, %edx
	movq	%rdx, -72(%rsp)
	movq	-40(%rsp), %rcx
	xorl	%edi, %ecx
	movq	%rcx, -40(%rsp)
	movl	%ecx, %eax
	xorl	-24(%rsp), %eax
	xorl	-32(%rsp), %edi
	movq	%rdi, -32(%rsp)
	shlq	$32, %rcx
	leaq	(%rdx,%rcx), %rcx
	movq	%rcx, 560(%r14)
	movq	%rdi, %rdx
	shlq	$32, %rdx
	orq	%rdx, %rax
	movq	%rax, 568(%r14)
	xorq	%rcx, %rbx
	movq	%rbx, 896(%r14)
	xorq	%rsi, %rax
	movq	%rax, 904(%r14)
	movzbl	384(%r14), %eax
	movzbl	(%r14,%rax), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %r12d
	shrl	$7, %r12d
	leal	(%r12,%r12,2), %edx
	leal	(%rdx,%r12,8), %edx
	shll	$4, %r12d
	orl	%edx, %r12d
	xorl	%ecx, %r12d
	movzbl	389(%r14), %ecx
	movzbl	(%r14,%rcx), %eax
	movl	%eax, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%eax, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	394(%r14), %ecx
	movzbl	(%r14,%rcx), %ebp
	movzbl	399(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ebp, %edi
	andl	$127, %edi
	addl	%edi, %edi
	movl	%ebp, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebx
	leal	(%rbx,%rsi,8), %ebx
	shll	$4, %esi
	orl	%ebx, %esi
	xorl	%edi, %esi
	movl	%r8d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%esi, %edi
	xorl	%ebp, %edi
	movl	%edi, -80(%rsp)
	xorl	%eax, %ebp
	movl	%r12d, %edi
	xorl	%ecx, %edi
	xorl	%edx, %edi
	xorl	%ebp, %edi
	movl	%edi, -48(%rsp)
	xorl	%r8d, %eax
	movl	%ecx, %edx
	xorl	%ecx, %eax
	andl	$127, %ecx
	addl	%ecx, %ecx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %edi
	leal	(%rdi,%rdx,8), %edi
	shll	$4, %edx
	orl	%edi, %edx
	xorl	%ecx, %edx
	xorl	%edx, %eax
	xorl	%esi, %eax
	movl	%eax, -88(%rsp)
	xorl	%r8d, %r12d
	xorl	%edx, %r12d
	xorl	%ebp, %r12d
	movzbl	388(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r9d, %ebx
	shrl	$7, %ebx
	leal	(%rbx,%rbx,2), %edx
	leal	(%rdx,%rbx,8), %edx
	shll	$4, %ebx
	orl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	393(%r14), %ecx
	movzbl	(%r14,%rcx), %r8d
	movl	%r8d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	movl	%r8d, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %esi
	leal	(%rsi,%rdx,8), %esi
	shll	$4, %edx
	orl	%esi, %edx
	xorl	%ecx, %edx
	movzbl	398(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %edi
	leal	(%rdi,%rsi,8), %edi
	shll	$4, %esi
	orl	%edi, %esi
	movl	%ecx, %edi
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %esi
	movzbl	387(%r14), %edi
	movzbl	(%r14,%rdi), %edi
	movl	%ebx, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movq	%rax, %r10
	movl	%r9d, %eax
	xorl	%edi, %eax
	xorl	%edx, %eax
	movl	%edi, %edx
	shrl	$7, %edx
	leal	(%rdx,%rdx,2), %ebp
	leal	(%rbp,%rdx,8), %ebp
	shll	$4, %edx
	orl	%ebp, %edx
	xorl	%esi, %eax
	xorl	%ecx, %eax
	movq	%rax, -96(%rsp)
	xorl	%r8d, %ecx
	xorl	%r9d, %r8d
	xorl	%edi, %r8d
	andl	$127, %edi
	addl	%edi, %edi
	xorl	%edi, %edx
	xorl	%edx, %r8d
	xorl	%esi, %r8d
	movq	%r8, -104(%rsp)
	xorl	%ecx, %r10d
	movq	%r10, -56(%rsp)
	xorl	%r9d, %ebx
	xorl	%edx, %ebx
	xorl	%ecx, %ebx
	movzbl	392(%r14), %eax
	movzbl	(%r14,%rax), %r9d
	movl	%r9d, %r8d
	shrl	$7, %r8d
	leal	(%r8,%r8,2), %ecx
	leal	(%rcx,%r8,8), %ecx
	shll	$4, %r8d
	orl	%ecx, %r8d
	movl	%r9d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %r8d
	movzbl	397(%r14), %ecx
	movzbl	(%r14,%rcx), %r10d
	movl	%r10d, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ecx
	leal	(%rcx,%rsi,8), %ecx
	shll	$4, %esi
	orl	%ecx, %esi
	movl	%r10d, %ecx
	andl	$127, %ecx
	addl	%ecx, %ecx
	xorl	%ecx, %esi
	movzbl	386(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	movl	%ecx, %edi
	shrl	$7, %edi
	leal	(%rdi,%rdi,2), %edx
	leal	(%rdx,%rdi,8), %edx
	shll	$4, %edi
	orl	%edx, %edi
	movl	%ecx, %edx
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %edi
	movzbl	391(%r14), %edx
	movzbl	(%r14,%rdx), %edx
	movl	%r8d, %ebp
	xorl	%edx, %ebp
	xorl	%esi, %ebp
	movl	%ebp, %eax
	movl	%r9d, %r15d
	xorl	%edx, %r15d
	xorl	%esi, %r15d
	movl	%edx, %esi
	shrl	$7, %esi
	leal	(%rsi,%rsi,2), %ebp
	leal	(%rbp,%rsi,8), %ebp
	shll	$4, %esi
	orl	%ebp, %esi
	xorl	%edi, %r15d
	xorl	%ecx, %r15d
	xorl	%r10d, %ecx
	xorl	%r9d, %r10d
	xorl	%edx, %r10d
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %esi
	xorl	%esi, %r10d
	xorl	%edi, %r10d
	xorl	%r9d, %r8d
	xorl	%esi, %r8d
	xorl	%ecx, %eax
	movl	%eax, -64(%rsp)
	xorl	%ecx, %r8d
	movzbl	396(%r14), %eax
	movzbl	(%r14,%rax), %ecx
	movl	%ecx, %ebp
	shrl	$7, %ebp
	leal	(%rbp,%rbp,2), %eax
	leal	(%rax,%rbp,8), %eax
	shll	$4, %ebp
	orl	%eax, %ebp
	movl	%ecx, %eax
	movl	%ecx, %r13d
	movl	%ecx, -112(%rsp)
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ebp
	movzbl	385(%r14), %eax
	movzbl	(%r14,%rax), %edi
	movl	%edi, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %eax
	leal	(%rax,%rcx,8), %eax
	shll	$4, %ecx
	orl	%eax, %ecx
	movl	%edi, %eax
	andl	$127, %eax
	addl	%eax, %eax
	xorl	%eax, %ecx
	movzbl	390(%r14), %eax
	movzbl	(%r14,%rax), %r11d
	movl	%r11d, %eax
	shrl	$7, %eax
	leal	(%rax,%rax,2), %esi
	leal	(%rsi,%rax,8), %esi
	shll	$4, %eax
	orl	%esi, %eax
	movl	%r11d, %esi
	andl	$127, %esi
	addl	%esi, %esi
	xorl	%esi, %eax
	movzbl	395(%r14), %esi
	movzbl	(%r14,%rsi), %edx
	movl	%ebp, %r9d
	xorl	%edx, %r9d
	xorl	%ecx, %r9d
	movl	%r13d, %esi
	xorl	%edx, %esi
	xorl	%ecx, %esi
	movl	%edx, %ecx
	shrl	$7, %ecx
	leal	(%rcx,%rcx,2), %r13d
	leal	(%r13,%rcx,8), %r13d
	shll	$4, %ecx
	orl	%r13d, %ecx
	xorl	%eax, %esi
	xorl	%r11d, %esi
	xorl	%edi, %r11d
	movl	-112(%rsp), %r13d
	xorl	%r13d, %edi
	xorl	%edx, %edi
	andl	$127, %edx
	addl	%edx, %edx
	xorl	%edx, %ecx
	xorl	%ecx, %edi
	xorl	%eax, %edi
	xorl	%r13d, %ebp
	xorl	%ecx, %ebp
	xorl	%r11d, %r9d
	xorl	%r11d, %ebp
	movl	-88(%rsp), %eax
	shll	$16, %eax
	orl	-48(%rsp), %eax
	shll	$24, %r12d
	orl	%eax, %r12d
	movl	-80(%rsp), %eax
	shll	$8, %eax
	orl	%eax, %r12d
	movq	-56(%rsp), %rax
	shlq	$32, %rax
	orq	%rax, %r12
	movq	-96(%rsp), %rax
	shlq	$40, %rax
	movq	-104(%rsp), %rcx
	shlq	$48, %rcx
	orq	%rax, %rcx
	shlq	$56, %rbx
	orq	%rcx, %rbx
	leaq	768(%r14), %rax
	movq	%rax, -80(%rsp)
	orq	%r12, %rbx
	leaq	256(%r14), %rax
	movq	%rax, -48(%rsp)
	shll	$16, %r10d
	orl	-64(%rsp), %r10d
	leaq	784(%r14), %rax
	movq	%rax, -88(%rsp)
	shll	$24, %r8d
	orl	%r10d, %r8d
	leaq	272(%r14), %rax
	movq	%rax, -96(%rsp)
	shll	$8, %r15d
	orl	%r15d, %r8d
	leaq	800(%r14), %rax
	movq	%rax, -104(%rsp)
	shlq	$32, %r9
	orq	%r9, %r8
	movq	-8(%rsp), %r9
	leaq	288(%r14), %rax
	movq	%rax, -56(%rsp)
	movq	%rbx, 736(%r14)
	shlq	$40, %rsi
	shlq	$48, %rdi
	orq	%rsi, %rdi
	shlq	$56, %rbp
	orq	%rdi, %rbp
	orq	%r8, %rbp
	movq	%rbp, 744(%r14)
	movq	-32(%rsp), %r8
	movzbl	%r8b, %eax
	movzbl	(%r14,%rax), %edx
	movq	%r8, %rax
	shrq	$24, %rax
	movzbl	(%r14,%rax), %eax
	movl	%r8d, %ecx
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	shll	$16, %eax
	shll	$24, %edx
	orl	%eax, %edx
	movl	%r8d, %eax
	shrl	$8, %eax
	movzbl	%al, %eax
	movzbl	(%r14,%rax), %eax
	shll	$8, %ecx
	orl	%eax, %edx
	orl	%ecx, %edx
	xorl	-72(%rsp), %edx
	xorl	$27, %edx
	movl	%edx, %eax
	movq	-40(%rsp), %r11
	xorl	%r11d, %eax
	movq	-24(%rsp), %rcx
	xorl	%edx, %ecx
	movl	%ecx, %edi
	movq	%rcx, %r10
	xorl	%r8d, %edi
	shlq	$32, %rax
	leaq	(%rdx,%rax), %rax
	movq	%rax, 576(%r14)
	movq	%rdi, %rcx
	shlq	$32, %rcx
	leaq	(%r10,%rcx), %rcx
	movq	%rcx, 584(%r14)
	xorq	%rax, %rbx
	movq	%rbx, 912(%r14)
	xorq	%rcx, %rbp
	movq	%rbp, 920(%r14)
	movzbl	415(%r14), %eax
	movzbl	(%r14,%rax), %esi
	movzbl	414(%r14), %eax
	movzbl	(%r14,%rax), %ebp
	movzbl	413(%r14), %eax
	movzbl	(%r14,%rax), %ebx
	movzbl	412(%r14), %eax
	movzbl	(%r14,%rax), %eax
	shlq	$24, %rsi
	shlq	$48, %rbp
	orq	%rsi, %rbp
	movzbl	410(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	shlq	$16, %rcx
	orq	%rcx, %rbp
	movzbl	409(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	shlq	$40, %rcx
	orq	%rcx, %rbp
	movzbl	405(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	shlq	$8, %rcx
	orq	%rcx, %rbp
	movzbl	404(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	shlq	$32, %rcx
	orq	%rcx, %rbp
	movzbl	400(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	orq	%rcx, %rbp
	movzbl	403(%r14), %ecx
	movzbl	(%r14,%rcx), %esi
	shlq	$56, %rsi
	orq	%rbp, %rsi
	movzbl	408(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	shlq	$8, %rbx
	shlq	$32, %rax
	orq	%rbx, %rax
	movzbl	402(%r14), %ebp
	movzbl	(%r14,%rbp), %ebp
	orq	%rcx, %rax
	movzbl	401(%r14), %ecx
	movzbl	(%r14,%rcx), %ecx
	shlq	$16, %rbp
	shlq	$40, %rcx
	orq	%rbp, %rcx
	movzbl	411(%r14), %ebp
	movzbl	(%r14,%rbp), %ebx
	shlq	$56, %rbx
	orq	%rax, %rbx
	movzbl	407(%r14), %eax
	movzbl	(%r14,%rax), %eax
	shlq	$24, %rax
	orq	%rax, %rbx
	movzbl	406(%r14), %eax
	movzbl	(%r14,%rax), %eax
	movq	%rsi, 752(%r14)
	shlq	$48, %rax
	orq	%rax, %rbx
	orq	%rcx, %rbx
	movq	%rbx, 760(%r14)
	movzbl	%dil, %eax
	movzbl	(%r14,%rax), %eax
	movq	%rdi, %rcx
	shrq	$24, %rcx
	movzbl	(%r14,%rcx), %ecx
	shll	$16, %ecx
	shll	$24, %eax
	orl	%ecx, %eax
	movl	%edi, %ecx
	shrl	$8, %edi
	movzbl	%dil, %edi
	movzbl	(%r14,%rdi), %edi
	orl	%edi, %eax
	leaq	816(%r14), %rdi
	movq	%rdi, -24(%rsp)
	shrl	$16, %ecx
	movzbl	%cl, %ecx
	movzbl	(%r14,%rcx), %ecx
	shll	$8, %ecx
	orl	%ecx, %eax
	leaq	304(%r14), %rcx
	movq	%rcx, -72(%rsp)
	xorl	$54, %eax
	xorl	%eax, %edx
	xorl	%r11d, %eax
	leaq	832(%r14), %rcx
	movq	%rcx, -40(%rsp)
	xorl	%eax, %r10d
	xorl	%eax, %r8d
	shlq	$32, %rax
	orq	%rax, %rdx
	movq	%r14, %rcx
	leaq	320(%r14), %rax
	movq	%rax, -32(%rsp)
	shlq	$32, %r8
	orq	%r8, %r10
	leaq	848(%r14), %rax
	movq	%rdx, 592(%r14)
	xorq	%rsi, %rdx
	leaq	336(%r14), %r8
	movq	%r10, 600(%r14)
	movq	%rdx, 928(%r14)
	leaq	864(%r14), %rdi
	xorq	%rbx, %r10
	leaq	352(%r14), %rbx
	movq	%r10, 936(%r14)
	movq	32(%r9), %rdx
	cmpl	$0, (%rdx)
	leaq	880(%r14), %r13
	leaq	368(%r14), %rbp
	leaq	896(%r14), %r12
	leaq	384(%r14), %r15
	leaq	912(%r14), %r14
	leaq	400(%rcx), %r10
	leaq	928(%rcx), %r11
	je	.LBB0_3
	movq	-16(%rsp), %rcx
	movl	$0, 432(%rcx)
	movl	$0, 440(%rcx)
	movl	$0, -64(%rsp)
	jmp	.LBB0_4
.LBB0_3:
	movq	16(%r9), %rdx
	movl	(%rdx), %r9d
	movq	-16(%rsp), %rcx
	movq	%rax, %rsi
	movl	440(%rcx), %eax
	movl	%eax, %edx
	andl	$1, %edx
	movl	%edx, -64(%rsp)
	movl	%edx, 432(%rcx)
	shrl	%eax
	shll	$9, %r9d
	orl	%eax, %r9d
	movq	%rsi, %rax
	movl	%r9d, 440(%rcx)
	movq	-8(%rsp), %r9
.LBB0_4:
	movq	(%r11), %rdx
	movq	8(%r11), %rcx
	movq	-16(%rsp), %rsi
	movq	%rcx, 424(%rsi)
	movq	%rdx, 416(%rsi)
	movq	(%r14), %rcx
	movq	8(%r14), %rdx
	movq	%rdx, 8(%r10)
	movq	%rcx, (%r10)
	movq	(%r12), %rcx
	movq	8(%r12), %rdx
	movq	%rdx, 8(%r15)
	movq	%rcx, (%r15)
	movq	(%r13), %rcx
	movq	8(%r13), %rdx
	movq	%rdx, 8(%rbp)
	movq	%rcx, (%rbp)
	movq	(%rdi), %rcx
	movq	8(%rdi), %rdx
	movq	%rdx, 8(%rbx)
	movq	%rcx, (%rbx)
	movq	(%rax), %rcx
	movq	8(%rax), %rax
	movq	%rax, 8(%r8)
	movq	%rcx, (%r8)
	movq	-40(%rsp), %rcx
	movq	(%rcx), %rax
	movq	8(%rcx), %rcx
	movq	-32(%rsp), %rdx
	movq	%rcx, 8(%rdx)
	movq	%rax, (%rdx)
	movq	-24(%rsp), %rcx
	movq	(%rcx), %rax
	movq	8(%rcx), %rcx
	movq	-72(%rsp), %rdx
	movq	%rcx, 8(%rdx)
	movq	%rax, (%rdx)
	movq	-104(%rsp), %rcx
	movq	(%rcx), %rax
	movq	8(%rcx), %rcx
	movq	-56(%rsp), %rdx
	movq	%rcx, 8(%rdx)
	movq	%rax, (%rdx)
	movq	-88(%rsp), %rcx
	movq	(%rcx), %rax
	movq	8(%rcx), %rcx
	movq	-96(%rsp), %rdx
	movq	%rcx, 8(%rdx)
	movq	%rax, (%rdx)
	movq	-80(%rsp), %rcx
	movq	(%rcx), %rax
	movq	8(%rcx), %rcx
	movq	-48(%rsp), %rdx
	movq	%rcx, 8(%rdx)
	movq	%rax, (%rdx)
	movq	40(%r9), %rax
	movq	416(%rsi), %rcx
	movq	424(%rsi), %rdx
	movq	%rcx, (%rax)
	movq	%rdx, 8(%rax)
	movq	48(%r9), %rax
	movl	-64(%rsp), %ecx
	movl	%ecx, (%rax)
.LBB0_5:
	xorl	%eax, %eax
	popq	%rbx
	.cfi_def_cfa_offset 48
	popq	%r12
	.cfi_def_cfa_offset 40
	popq	%r13
	.cfi_def_cfa_offset 32
	popq	%r14
	.cfi_def_cfa_offset 24
	popq	%r15
	.cfi_def_cfa_offset 16
	popq	%rbp
	.cfi_def_cfa_offset 8
	retq
.Lfunc_end0:
	.size	eval, .Lfunc_end0-eval
	.cfi_endproc


	.section	".note.GNU-stack","",@progbits
